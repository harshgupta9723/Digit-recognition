{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RsxhDCJ9zv6xWgz9uyA4cQzESHCCA96u",
      "authorship_tag": "ABX9TyOpCBjmdyLpoJi1QcCEJ9On",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshgupta9723/Digit-recognition/blob/master/Digit_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xh4mEr0fiVR"
      },
      "source": [
        "# DIGIT RECOGNITION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iUGvZBjhr0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16eb7bf-5a6a-4c3d-aa82-8bd83a6706e4"
      },
      "source": [
        "#import libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics.classification import accuracy_score, log_loss"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09lQKD-BOgQK"
      },
      "source": [
        "# Data analysis and visualization on MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st43CAS_kffr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc232813-271d-4538-cec4-7279347ac753"
      },
      "source": [
        "# Importing mnist data\n",
        "# Data is available in splited format of train and set\n",
        "\n",
        "project_data = pd.read_csv('/content/drive/My Drive/Project ideas/digit_recognition/data/digit-recognizer/train.csv')\n",
        "\n",
        "# print row of project_data\n",
        "print(project_data.head(5))\n",
        "\n",
        "# save the labels into a variable label\n",
        "# lable conatins the digit which is represented by pixels\n",
        "\n",
        "label = project_data['label']\n",
        "\n",
        "# Drop the label feature and store the pixel data into variable data.\n",
        "# each row in data contains 784 pixels i.e each image is consists of 784 pixels\n",
        "\n",
        "data = project_data.drop(\"label\",axis=1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
            "0      1       0       0       0  ...         0         0         0         0\n",
            "1      0       0       0       0  ...         0         0         0         0\n",
            "2      1       0       0       0  ...         0         0         0         0\n",
            "3      4       0       0       0  ...         0         0         0         0\n",
            "4      0       0       0       0  ...         0         0         0         0\n",
            "\n",
            "[5 rows x 785 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkykGd8XyVeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f43143-18fc-4d55-d9cd-cda7497c5e18"
      },
      "source": [
        "# Explaination about image\n",
        "\n",
        "print(\"This represents (no. of rows, no. of columns) in the data - \",data.shape)\n",
        "print(\"no. of lables - \",label.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This represents (no. of rows, no. of columns) in the data -  (42000, 784)\n",
            "no. of lables -  (42000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RACWKv9eV5Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "e3155a07-e57a-4984-fb63-77d66c39d186"
      },
      "source": [
        "# display or plot a number.\n",
        "\n",
        "\n",
        "# data.iloc[1] - function is used to get row of given index (mainly used when data is not provided in index)\n",
        "# .to_numpy() - function is used to convert given row into numpy array, to further convert it into (28,28) pixels\n",
        "# .reshape(28,28) - function is used to convert 784 pixel data point into 28 rows and 28 columns\n",
        "\n",
        "index = 10\n",
        "\n",
        "grid_data = data.iloc[index].to_numpy().reshape(28,28)\n",
        "\n",
        "# figsize is used to define size of the image\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "# imshow plot numpy array (28,28)\n",
        "plt.imshow(grid_data,cmap = \"gray\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe7af59ef98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfu5XCcx3C5b"
      },
      "source": [
        "# Split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgGQgKdF3CE7"
      },
      "source": [
        "X = data\n",
        "y = label\n",
        "\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(X, y, stratify=y, test_size=0.2)\n",
        "xtrain, xcv, ytrain, ycv = train_test_split(xtrain, ytrain, stratify=ytrain, test_size=0.2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgrrp_3XOb_s"
      },
      "source": [
        "# Encoding techniques "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQtKZAg9ObMY"
      },
      "source": [
        "# Data-preprocessing: normalizing the data\n",
        "\n",
        "xtrain_normalized = preprocessing.normalize(xtrain)\n",
        "xtest_normalized = preprocessing.normalize(xtest)\n",
        "xcv_normalized = preprocessing.normalize(xcv)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaO5htCO71I-"
      },
      "source": [
        "# Model taining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIkb1q4j7-7E"
      },
      "source": [
        "# hyper parameter tuning of sgd classifier\n",
        "\n",
        "# declare range of alpha(hyper parameter)\n",
        "alpha = [10 ** x for x in range(-6, 3)]\n",
        "cv_log_error_array = []\n",
        "for i in alpha:\n",
        "    print(\"for alpha =\", i)\n",
        "\n",
        "    # use class_weight = 'balanced' for imbalanced dataset\n",
        "    clf = SGDClassifier(class_weight='balanced', alpha=i, penalty='l2', loss='log', random_state=42)\n",
        "    clf.fit(xtrain_normalized, ytrain)\n",
        "\n",
        "    # calibrated classifier to calculate the probablity of predicted categorys\n",
        "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
        "    sig_clf.fit(xtrain_normalized, ytrain)\n",
        "    sig_clf_probs = sig_clf.predict_proba(xcv_normalized)\n",
        "    cv_log_error_array.append(log_loss(ycv, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n",
        "\n",
        "    # to avoid rounding error while multiplying probabilites we use log-probability estimates\n",
        "    print(\"Log Loss :\",log_loss(ycv, sig_clf_probs)) \n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(alpha, cv_log_error_array,c='g')\n",
        "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
        "    ax.annotate((alpha[i],str(txt)), (alpha[i],cv_log_error_array[i]))\n",
        "plt.grid()\n",
        "plt.title(\"Cross Validation Error for each alpha\")\n",
        "plt.xlabel(\"Alpha i's\")\n",
        "plt.ylabel(\"Error measure\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# get best alpha for minimum log loss\n",
        "best_alpha = np.argmin(cv_log_error_array)\n",
        "\n",
        "# train model for on best hyper parameter\n",
        "clf = SGDClassifier(class_weight='balanced', alpha=alpha[best_alpha], penalty='l2', loss='log',random_state=42)\n",
        "clf.fit(xtrain_normalized, ytrain)\n",
        "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
        "sig_clf.fit(xtrain_normalized, ytrain)\n",
        "\n",
        "predict_y = sig_clf.predict_proba(xtrain_normalized)\n",
        "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(ytrain, predict_y, labels=clf.classes_, eps=1e-15))\n",
        "predict_y = sig_clf.predict_proba(xcv_normalized)\n",
        "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(ycv, predict_y, labels=clf.classes_, eps=1e-15))\n",
        "predict_y = sig_clf.predict_proba(xtest_normalized)\n",
        "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(ytest, predict_y, labels=clf.classes_, eps=1e-15))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYaLJu4E7_Ib"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}